{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import fire\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "from jax import jit\n",
    "from onnxruntime import (\n",
    "    GraphOptimizationLevel, InferenceSession,\n",
    "    SessionOptions, get_available_providers\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# !pip install -U onnxruntime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "CURRENT_DIR = os.path.realpath(os.path.dirname(''))\n",
    "NUM_THREADS = min(4, os.cpu_count())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def create_model_for_provider(\n",
    "    model_path: str,\n",
    "    provider: str = 'auto',\n",
    "    num_threads=None\n",
    ") -> InferenceSession:\n",
    "    if provider == 'auto':\n",
    "        if 'CUDAExecutionProvider' in get_available_providers():\n",
    "            provider = 'CUDAExecutionProvider'\n",
    "        else:\n",
    "            provider = 'CPUExecutionProvider'\n",
    "        print('model provider', provider)\n",
    "    assert provider in get_available_providers(), \\\n",
    "        f\"provider {provider} not found, {get_available_providers()}\"\n",
    "    \n",
    "    # Few properties that might have an impact on performances (provided by MS)\n",
    "    options = SessionOptions()\n",
    "    if num_threads is not None:\n",
    "        options.intra_op_num_threads = num_threads\n",
    "    else:\n",
    "        options.intra_op_num_threads = int(os.environ.get('NUM_THREADS', NUM_THREADS))\n",
    "    options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    # options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "    \n",
    "    # Load the model as a graph and prepare the CPU backend\n",
    "    session = InferenceSession(model_path, options, providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session\n",
    "\n",
    "\n",
    "def get_video(input_file):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    c = 0\n",
    "    while True:\n",
    "        if cap.grab():\n",
    "            flag, frame = cap.retrieve()\n",
    "            if not flag:\n",
    "                continue\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                src = np.expand_dims(np.transpose(frame, (2, 0, 1)), 0).astype(np.float32) / 255.0\n",
    "                yield src\n",
    "            c += 1\n",
    "            if c >= 50:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "\n",
    "@jit\n",
    "def compute_border(fgr, pha, border):\n",
    "    output_img_border = fgr * pha + (1 - pha) * border\n",
    "    output_img_border = np.clip(output_img_border, 0.0, 1.0)\n",
    "    output_img_border = (output_img_border * 255.0).astype('uint8')\n",
    "    ipha = ((pha > 0.2) * 255).astype('uint8')\n",
    "    return output_img_border, ipha\n",
    "\n",
    "@jit\n",
    "def compute_border_2(output_img_border, img_dilation_filter, green):\n",
    "    return (output_img_border * img_dilation_filter) + (1 - img_dilation_filter) * green * 255\n",
    "\n",
    "\n",
    "@jit\n",
    "def compute_without_border(fgr, pha, green):\n",
    "    output_img = fgr * pha + (1 - pha) * green\n",
    "    output_img = np.clip(output_img, 0.0, 1.0)\n",
    "    output_img = (output_img * 255.0)\n",
    "    return output_img\n",
    "\n",
    "def write_frame(fgr, pha, border, green, use_border):\n",
    "    fgr = np.transpose(fgr, [0, 2, 3, 1])\n",
    "    pha = np.transpose(pha, [0, 2, 3, 1])\n",
    "    if use_border:\n",
    "        output_img_border, ipha = compute_border(fgr, pha, border)\n",
    "        output_img_border = np.array(output_img_border)\n",
    "        ipha = np.array(ipha)\n",
    "\n",
    "        dilation = cv2.dilate(np.array(ipha[0]), np.ones((5, 5)), iterations=1)\n",
    "        img_dilation = np.expand_dims(np.expand_dims(dilation, 0), -1)\n",
    "        img_dilation_filter = img_dilation.astype('float32') / 255.0\n",
    "\n",
    "        output_img_border = np.array(\n",
    "            compute_border_2(\n",
    "                output_img_border, img_dilation_filter, green\n",
    "            )\n",
    "        ).astype('uint8')\n",
    "\n",
    "        output_img = output_img_border\n",
    "    else:\n",
    "        output_img = np.array(compute_without_border(fgr, pha, green)).astype('uint8')\n",
    "    oi = cv2.cvtColor(output_img[0], cv2.COLOR_RGB2BGR)\n",
    "    return oi\n",
    "\n",
    "\n",
    "def generate_result(input_file, all_frames, sess, model_path, downsample):\n",
    "    pbar = tqdm(\n",
    "        m_get_video(input_file=input_file),\n",
    "        total=math.ceil(all_frames)\n",
    "    )\n",
    "    rec = [ np.zeros([1, 1, 1, 1], dtype=np.float32) ] * 4  # Must match dtype of the model.\n",
    "    downsample_ratio = np.array([downsample], dtype=np.float32)  # dtype always FP32\n",
    "    for src in pbar:\n",
    "        batch_inputs = src\n",
    "        if 'fp16' in model_path:\n",
    "            batch_inputs = batch_inputs.astype('float16')\n",
    "            rec = [x.astype('float16') for x in rec]\n",
    "        elif 'fp32' in model_path:\n",
    "            batch_inputs = batch_inputs.astype('float32')\n",
    "            rec = [x.astype('float32') for x in rec]\n",
    "        fgr, pha, *rec = sess.run([], {\n",
    "            'src': batch_inputs,\n",
    "            'r1i': rec[0][-1:], 'r2i': rec[1][-1:], 'r3i': rec[2][-1:], 'r4i': rec[3][-1:],\n",
    "            'downsample_ratio': downsample_ratio\n",
    "        })\n",
    "        yield fgr, pha\n",
    "\n",
    "\n",
    "def convert(\n",
    "    input_file,\n",
    "    output_file,\n",
    "    model_path=os.path.join(CURRENT_DIR, 'rvm_mobilenetv3_int8.onnx'),\n",
    "    downsample=0.5,\n",
    "    green_color=[0, 255, 0],\n",
    "    use_border=False,\n",
    "    border_color=[255, 255, 255],\n",
    "    num_threads=None\n",
    "):\n",
    "    assert os.path.exists(input_file), 'Input file not found'\n",
    "    assert os.path.exists(model_path), 'Model not found'\n",
    "    ss = time.time()\n",
    "\n",
    "    sess = create_model_for_provider(model_path, num_threads=num_threads)\n",
    "\n",
    "    green = np.array(green_color).reshape([1, 1, 3]) / 255.\n",
    "    border = np.array(border_color).reshape([1, 1, 3]) / 255.\n",
    "\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    all_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = float(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    cap.release()\n",
    "\n",
    "    p, q = m_write_frame(fps, width, height, border, green, use_border)\n",
    "    for fgr, pha in generate_result(input_file, all_frames, sess, model_path, downsample):\n",
    "        q.put([fgr, pha], False)\n",
    "    q.put(None, False)\n",
    "    p.join()\n",
    "\n",
    "    # combine_audio(f.name, input_file, output_file)\n",
    "    print(time.time() - ss)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def m_write_frame_process(\n",
    "    q,\n",
    "    fps, width, height,\n",
    "    border, green, use_border\n",
    "):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter('tmp.mp4', fourcc, fps, (width, height))\n",
    "    while True:\n",
    "        r = q.get()\n",
    "        if r is None:\n",
    "            break\n",
    "        fgr, pha = r\n",
    "        fgr = np.transpose(fgr, [0, 2, 3, 1])\n",
    "        pha = np.transpose(pha, [0, 2, 3, 1])\n",
    "        if use_border:\n",
    "            output_img_border, ipha = compute_border(fgr, pha, border)\n",
    "            output_img_border = np.array(output_img_border)\n",
    "            ipha = np.array(ipha)\n",
    "\n",
    "            dilation = cv2.dilate(np.array(ipha[0]), np.ones((5, 5)), iterations=1)\n",
    "            img_dilation = np.expand_dims(np.expand_dims(dilation, 0), -1)\n",
    "            img_dilation_filter = img_dilation.astype('float32') / 255.0\n",
    "\n",
    "            output_img_border = np.array(\n",
    "                compute_border_2(\n",
    "                    output_img_border, img_dilation_filter, green\n",
    "                )\n",
    "            ).astype('uint8')\n",
    "\n",
    "            output_img = output_img_border\n",
    "        else:\n",
    "            output_img = np.array(compute_without_border(fgr, pha, green)).astype('uint8')\n",
    "        oi = cv2.cvtColor(output_img[0], cv2.COLOR_RGB2BGR)\n",
    "        out.write(oi)\n",
    "    out.release()\n",
    "\n",
    "    \n",
    "def m_write_frame(fps, width, height, border, green, use_border):\n",
    "    from multiprocessing import Process, Queue\n",
    "    q = Queue()\n",
    "    p = Process(target=m_write_frame_process, args=(q, fps, width, height, border, green, use_border))\n",
    "    p.start()\n",
    "    return p, q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def m_get_video_process(q, input_file):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "    c = 0\n",
    "    while True:\n",
    "        if cap.grab():\n",
    "            flag, frame = cap.retrieve()\n",
    "            if not flag:\n",
    "                continue\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                src = np.expand_dims(np.transpose(frame, (2, 0, 1)), 0).astype(np.float32) / 255.0\n",
    "                q.put(src)\n",
    "            c += 1\n",
    "            if c >= 50:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    q.put(None)\n",
    "\n",
    "\n",
    "def m_get_video(input_file):\n",
    "    from multiprocessing import Process, Queue\n",
    "    q = Queue()\n",
    "    p = Process(target=m_get_video_process, args=(q, input_file))\n",
    "    p.start()\n",
    "    while True:\n",
    "        x = q.get()\n",
    "        if x is None:\n",
    "            break\n",
    "        yield x\n",
    "    p.join()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "!ls ../video_matting"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__init__.py  merge.py\t  rvm_mobilenetv3_fp32.onnx  rvm.py\r\n",
      "__main__.py  __pycache__  rvm_mobilenetv3_int8.onnx  video_matting_cli.py\r\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# convert('../IMG_5022.MOV', './out.mp4', '../video_matting/rvm_mobilenetv3_int8.onnx', num_threads=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# convert('../IMG_5022.MOV', './out.mp4', '../video_matting/rvm_mobilenetv3_int8.onnx', num_threads=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "convert('../IMG_5022.MOV', './out.mp4', '../video_matting/rvm_mobilenetv3_fp32.onnx', num_threads=4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model provider CPUExecutionProvider\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 1/365 [00:01<09:18,  1.53s/it]WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      " 14%|█▎        | 50/365 [00:35<03:41,  1.42it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35.39338755607605\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}